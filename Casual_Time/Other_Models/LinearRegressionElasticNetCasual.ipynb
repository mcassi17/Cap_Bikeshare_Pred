{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime \n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.utils import shuffle\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_data(file):\n",
    "    bikeshare_machine = pd.read_csv(file, \n",
    "                        parse_dates=['Start date', 'End date'])\n",
    "    bikeshare_machine.drop('Unnamed: 0', 1, inplace=True)\n",
    "    included_cols = ['start_station','end_station','Member Type','time_diff','season','mnth','holiday',\n",
    "                     'weekday','workingday','weathersit','temp','hum','windspeed','miles',\n",
    "                     'rush_hour','metro_dist','landmark_dist_start','landmark_dist_end']\n",
    "    bikeshare_machine = bikeshare_machine[included_cols]\n",
    "    bikeshare_machine['season'] = bikeshare_machine['season'].astype('category')\n",
    "    bikeshare_machine['mnth'] = bikeshare_machine['mnth'].astype('category')\n",
    "    bikeshare_machine['holiday'] = bikeshare_machine['holiday'].astype('category')\n",
    "    bikeshare_machine['weekday'] = bikeshare_machine['weekday'].astype('category')\n",
    "    bikeshare_machine['workingday'] = bikeshare_machine['workingday'].astype('category')\n",
    "    bikeshare_machine['weathersit'] = bikeshare_machine['weathersit'].astype('category')\n",
    "    bikeshare_machine['Member Type'] = bikeshare_machine['Member Type'].astype('category')\n",
    "    bikeshare_machine['start_station'] = bikeshare_machine['start_station'].astype('category')\n",
    "    bikeshare_machine['end_station'] = bikeshare_machine['end_station'].astype('category')\n",
    "    bikeshare_machine['rush_hour'] = bikeshare_machine['rush_hour'].astype('category')\n",
    "    col_names = ['start_station', 'end_station','member_type','time_diff','season','month','holiday',\n",
    "             'weekday','work_day','weather_cat','temperature','humidity','windspeed','miles','rush_hour',\n",
    "                'metro_dist','landmark_dist_start','landmark_dist_end']\n",
    "    bikeshare_machine.columns = col_names\n",
    "    tmin = -8\n",
    "    tmax = 39\n",
    "    hum_max = 100\n",
    "    wind_max = 67\n",
    "    bikeshare_machine['temp'] = bikeshare_machine['temperature'] * (tmax - tmin) + tmin\n",
    "    bikeshare_machine['hum'] = bikeshare_machine['humidity'] * 100\n",
    "    bikeshare_machine['wind'] = bikeshare_machine['windspeed'] * 67\n",
    "    bikeshare_machine = pd.get_dummies(bikeshare_machine, \n",
    "                                 columns=['rush_hour','member_type','holiday','work_day'], drop_first=True)\n",
    "    bikeshare_machine = pd.get_dummies(bikeshare_machine, \n",
    "                                 columns=['start_station','end_station','season','month','weekday','weather_cat'])\n",
    "    bikeshare_machine = shuffle(bikeshare_machine)\n",
    "    return bikeshare_machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = '/Users/matthewcassi/Documents/Bike-Sharing-Dataset/Bikeshare_Time_Prediction/Casual_RushMetro/landmark_casual.csv'\n",
    "bikeshare_machine = set_data(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_diff</th>\n",
       "      <th>miles</th>\n",
       "      <th>metro_dist</th>\n",
       "      <th>landmark_dist_start</th>\n",
       "      <th>landmark_dist_end</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>wind</th>\n",
       "      <th>rush_hour_1</th>\n",
       "      <th>holiday_1</th>\n",
       "      <th>...</th>\n",
       "      <th>weekday_0</th>\n",
       "      <th>weekday_1</th>\n",
       "      <th>weekday_2</th>\n",
       "      <th>weekday_3</th>\n",
       "      <th>weekday_4</th>\n",
       "      <th>weekday_5</th>\n",
       "      <th>weekday_6</th>\n",
       "      <th>weather_cat_1</th>\n",
       "      <th>weather_cat_2</th>\n",
       "      <th>weather_cat_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121569</th>\n",
       "      <td>5.250</td>\n",
       "      <td>0.287267</td>\n",
       "      <td>0.129048</td>\n",
       "      <td>0.086349</td>\n",
       "      <td>0.285993</td>\n",
       "      <td>23.176651</td>\n",
       "      <td>59.1250</td>\n",
       "      <td>12.249811</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129200</th>\n",
       "      <td>10.633</td>\n",
       "      <td>0.775454</td>\n",
       "      <td>0.328093</td>\n",
       "      <td>0.306432</td>\n",
       "      <td>0.916964</td>\n",
       "      <td>26.153349</td>\n",
       "      <td>63.7917</td>\n",
       "      <td>5.459106</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118317</th>\n",
       "      <td>71.450</td>\n",
       "      <td>2.337246</td>\n",
       "      <td>0.427048</td>\n",
       "      <td>0.466544</td>\n",
       "      <td>0.411781</td>\n",
       "      <td>25.800849</td>\n",
       "      <td>60.4167</td>\n",
       "      <td>16.417211</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140498</th>\n",
       "      <td>32.450</td>\n",
       "      <td>2.785085</td>\n",
       "      <td>0.093903</td>\n",
       "      <td>0.378039</td>\n",
       "      <td>1.232900</td>\n",
       "      <td>6.765849</td>\n",
       "      <td>62.5833</td>\n",
       "      <td>6.750518</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92126</th>\n",
       "      <td>25.200</td>\n",
       "      <td>1.565285</td>\n",
       "      <td>0.141728</td>\n",
       "      <td>0.206375</td>\n",
       "      <td>0.298604</td>\n",
       "      <td>25.231773</td>\n",
       "      <td>56.1765</td>\n",
       "      <td>20.412153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 295 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        time_diff     miles  metro_dist  landmark_dist_start  \\\n",
       "121569      5.250  0.287267    0.129048             0.086349   \n",
       "129200     10.633  0.775454    0.328093             0.306432   \n",
       "118317     71.450  2.337246    0.427048             0.466544   \n",
       "140498     32.450  2.785085    0.093903             0.378039   \n",
       "92126      25.200  1.565285    0.141728             0.206375   \n",
       "\n",
       "        landmark_dist_end       temp      hum       wind  rush_hour_1  \\\n",
       "121569           0.285993  23.176651  59.1250  12.249811            0   \n",
       "129200           0.916964  26.153349  63.7917   5.459106            0   \n",
       "118317           0.411781  25.800849  60.4167  16.417211            0   \n",
       "140498           1.232900   6.765849  62.5833   6.750518            0   \n",
       "92126            0.298604  25.231773  56.1765  20.412153            0   \n",
       "\n",
       "        holiday_1      ...        weekday_0  weekday_1  weekday_2  weekday_3  \\\n",
       "121569          0      ...                0          0          0          0   \n",
       "129200          1      ...                0          1          0          0   \n",
       "118317          0      ...                1          0          0          0   \n",
       "140498          0      ...                0          0          0          0   \n",
       "92126           0      ...                1          0          0          0   \n",
       "\n",
       "        weekday_4  weekday_5  weekday_6  weather_cat_1  weather_cat_2  \\\n",
       "121569          0          1          0              1              0   \n",
       "129200          0          0          0              0              1   \n",
       "118317          0          0          0              1              0   \n",
       "140498          0          1          0              1              0   \n",
       "92126           0          0          0              1              0   \n",
       "\n",
       "        weather_cat_3  \n",
       "121569              0  \n",
       "129200              0  \n",
       "118317              0  \n",
       "140498              0  \n",
       "92126               0  \n",
       "\n",
       "[5 rows x 295 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikeshare_machine = bikeshare_machine.drop(['temperature', 'humidity', 'windspeed'], 1)\n",
    "bikeshare_machine = bikeshare_machine.rename(columns = {'member_type_Registered':'member_type'})\n",
    "bikeshare_machine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - Remove Some Variables that are correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Leave workday, drop weekdays, leave season, drop month\n",
    "# Workday overlaps with workday/not workday and months overlap with seasons\n",
    "remove_cols = ['weekday_0', 'weekday_1','weekday_2','weekday_3','weekday_4','weekday_5','weekday_6', \n",
    "              'month_1','month_2','month_3','month_4','month_5','month_6','month_7','month_8','month_9',\n",
    "              'month_10','month_11','month_12','time_diff']\n",
    "X1 = np.matrix(bikeshare_machine.drop(remove_cols, 1))\n",
    "y1 = bikeshare_machine['time_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((152719, 275), (50907, 275), (152719,), (50907,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training and testing sets and check the shape\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size = 0.25)\n",
    "X1_train.shape, X1_test.shape, y1_train.shape, y1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'l1_ratio': array([ 0.003]), 'alpha': array([ 0.01])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "parameters = {'l1_ratio':np.arange(0.003,1,30),\n",
    "             'alpha': np.arange(0.01, 1, 30)}\n",
    "elastic1 = ElasticNet()\n",
    "ecv1 = GridSearchCV(elastic1, param_grid=parameters, cv=5)\n",
    "ecv1.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ecv_pred1 = ecv1.predict(X1_test)\n",
    "ecv_score1 = ecv1.score(X1_test, y1_test)\n",
    "ecv_mse1 = mean_squared_error(y1_test, ecv_pred1)\n",
    "ecv_rmse1 = np.sqrt(ecv_mse1)\n",
    "ecv_evar1 = explained_variance_score(y1_test, ecv_pred1)\n",
    "adjustedr1 = 1 - (1-ecv_score1)*(len(y1_test)-1)/(len(y1_test)-X1_test.shape[1]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.13673997794312931,\n",
       " 282.46990184344912,\n",
       " 16.806840923964536,\n",
       " 0.13682456882800387,\n",
       " 0.13205121994771862)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecv_score1, ecv_mse1, ecv_rmse1, ecv_evar1, adjustedr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - Try reverse of Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop workday, leave weekdays, drop season, leave month\n",
    "# Workday overlaps with workday/not workday and months overlap with seasons\n",
    "remove_cols = ['work_day_1','season_1', 'season_2', 'season_3', 'season_4','time_diff']\n",
    "X2 = bikeshare_machine.drop(remove_cols, 1)\n",
    "y2 = bikeshare_machine['time_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((152719, 289), (50907, 289), (152719,), (50907,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training and testing sets and check the shape\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size = 0.25, random_state=17)\n",
    "X2_train.shape, X2_test.shape, y2_train.shape, y2_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'l1_ratio': array([ 0.003]), 'alpha': array([ 0.01])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "parameters = {'l1_ratio':np.arange(0.003,1,30),\n",
    "             'alpha': np.arange(0.01, 1, 30)}\n",
    "elastic2 = ElasticNet()\n",
    "ecv2 = GridSearchCV(elastic1, param_grid=parameters, cv=5)\n",
    "ecv2.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ecv_pred2 = ecv2.predict(X2_test)\n",
    "ecv_score2 = ecv2.score(X2_test, y2_test)\n",
    "ecv_mse2 = mean_squared_error(y2_test, ecv_pred2)\n",
    "ecv_rmse2 = np.sqrt(ecv_mse2)\n",
    "ecv_evar2 = explained_variance_score(y2_test, ecv_pred2)\n",
    "adjustedr2 = 1 - (1-ecv_score2)*(len(y2_test)-1)/(len(y2_test)-X2_test.shape[1]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.14278292615357191,\n",
       " 285.13481173345605,\n",
       " 16.885935323027152,\n",
       " 0.14278556812696541,\n",
       " 0.13788860736064423)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecv_score2, ecv_mse2, ecv_rmse2, ecv_evar2, adjustedr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 - All variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keep all but time_diff\n",
    "X3 = bikeshare_machine.drop('time_diff', 1)\n",
    "y3 = bikeshare_machine['time_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((152719, 294), (50907, 294), (152719,), (50907,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training and testing sets and check the shape\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size = 0.25, random_state=17)\n",
    "X3_train.shape, X3_test.shape, y3_train.shape, y3_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'l1_ratio': array([ 0.003]), 'alpha': array([ 0.01])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "parameters = {'l1_ratio':np.arange(0.003,1,30),\n",
    "             'alpha': np.arange(0.01, 1, 30)}\n",
    "elastic3 = ElasticNet()\n",
    "ecv3 = GridSearchCV(elastic3, param_grid=parameters, cv=5)\n",
    "ecv3.fit(X3_train, y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ecv_pred3 = ecv3.predict(X3_test)\n",
    "ecv_score3 = ecv3.score(X3_test, y3_test)\n",
    "ecv_mse3 = mean_squared_error(y3_test, ecv_pred3)\n",
    "ecv_rmse3 = np.sqrt(ecv_mse3)\n",
    "ecv_evar3 = explained_variance_score(y3_test, ecv_pred3)\n",
    "adjustedr3 = 1 - (1-ecv_score3)*(len(y3_test)-1)/(len(y3_test)-X3_test.shape[1]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.14263606303810028,\n",
       " 285.18366258822579,\n",
       " 16.887381756454307,\n",
       " 0.14263857164274962,\n",
       " 0.13765572245747126)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecv_score3, ecv_mse3, ecv_rmse3, ecv_evar3, adjustedr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
